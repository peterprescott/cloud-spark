
@article{FChangEtAl2008,
  title = {Bigtable: A Distributed Storage System for Structured Data},
  shorttitle = {Bigtable},
  author = {Chang, Fay and Dean, Jeffrey and Ghemawat, Sanjay and Hsieh, Wilson C. and Wallach, Deborah A. and Burrows, Mike and Chandra, Tushar and Fikes, Andrew and Gruber, Robert E.},
  year = {2008},
  journal = {ACM Transactions on Computer Systems (TOCS)},
  volume = {26},
  number = {2},
  pages = {1--26},
  publisher = {{ACM New York, NY, USA}},
  file = {/home/peterprescott/Zotero/storage/HM5GNDC6/Chang et al. - 2008 - Bigtable A distributed storage system for structu.pdf;/home/peterprescott/Zotero/storage/LXVTXRDG/1365815.html}
}

@article{JDeanGhemawat2008,
  title = {{{MapReduce}}: Simplified Data Processing on Large Clusters},
  shorttitle = {{{MapReduce}}},
  author = {Dean, Jeffrey and Ghemawat, Sanjay},
  year = {2008},
  month = jan,
  journal = {Communications of the ACM},
  volume = {51},
  number = {1},
  pages = {107--113},
  issn = {0001-0782, 1557-7317},
  doi = {10.1145/1327452.1327492},
  abstract = {MapReduce is a programming model and an associated implementation for processing and generating large data sets. Users specify a map function that processes a key/value pair to generate a set of intermediate key/value pairs, and a reduce function that merges all intermediate values associated with the same intermediate key. Many real world tasks are expressible in this model, as shown in the paper.},
  langid = {english},
  file = {/home/peterprescott/Zotero/storage/S4A42LQN/Dean and Ghemawat - 2008 - MapReduce simplified data processing on large clu.pdf}
}

@inproceedings{KShvachkoEtAl2010,
  title = {The {{Hadoop Distributed File System}}},
  booktitle = {2010 {{IEEE}} 26th {{Symposium}} on {{Mass Storage Systems}} and {{Technologies}} ({{MSST}})},
  author = {Shvachko, K. and Kuang, H. and Radia, S. and Chansler, R.},
  year = {2010},
  month = may,
  pages = {1--10},
  issn = {2160-1968},
  doi = {10.1109/MSST.2010.5496972},
  abstract = {The Hadoop Distributed File System (HDFS) is designed to store very large data sets reliably, and to stream those data sets at high bandwidth to user applications. In a large cluster, thousands of servers both host directly attached storage and execute user application tasks. By distributing storage and computation across many servers, the resource can grow with demand while remaining economical at every size. We describe the architecture of HDFS and report on experience using HDFS to manage 25 petabytes of enterprise data at Yahoo!.},
  keywords = {Bandwidth,Clustering algorithms,Computer architecture,Concurrent computing,data storage,data stream,Distributed computing,distributed databases,distributed file system,enterprise data,Facebook,File servers,File systems,Hadoop,Hadoop distributed file system,HDFS,Internet,network operating systems,Protection,Protocols,Yahoo!},
  file = {/home/peterprescott/Zotero/storage/24XLR87Q/Shvachko et al. - 2010 - The Hadoop Distributed File System.pdf;/home/peterprescott/Zotero/storage/87F7NIRK/5496972.html}
}

@inproceedings{MArmbrustEtAl2015,
  title = {Spark {{SQL}}: Relational {{Data Processing}} in {{Spark}}},
  shorttitle = {Spark {{SQL}}},
  booktitle = {Proceedings of the 2015 {{ACM SIGMOD International Conference}} on {{Management}} of {{Data}}},
  author = {Armbrust, Michael and Xin, Reynold S. and Lian, Cheng and Huai, Yin and Liu, Davies and Bradley, Joseph K. and Meng, Xiangrui and Kaftan, Tomer and Franklin, Michael J. and Ghodsi, Ali and Zaharia, Matei},
  year = {2015},
  month = may,
  series = {{{SIGMOD}} '15},
  pages = {1383--1394},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/2723372.2742797},
  abstract = {Spark SQL is a new module in Apache Spark that integrates relational processing with Spark's functional programming API. Built on our experience with Shark, Spark SQL lets Spark programmers leverage the benefits of relational processing (e.g. declarative queries and optimized storage), and lets SQL users call complex analytics libraries in Spark (e.g. machine learning). Compared to previous systems, Spark SQL makes two main additions. First, it offers much tighter integration between relational and procedural processing, through a declarative DataFrame API that integrates with procedural Spark code. Second, it includes a highly extensible optimizer, Catalyst, built using features of the Scala programming language, that makes it easy to add composable rules, control code generation, and define extension points. Using Catalyst, we have built a variety of features (e.g. schema inference for JSON, machine learning types, and query federation to external databases) tailored for the complex needs of modern data analysis. We see Spark SQL as an evolution of both SQL-on-Spark and of Spark itself, offering richer APIs and optimizations while keeping the benefits of the Spark programming model.},
  isbn = {978-1-4503-2758-9},
  keywords = {data warehouse,databases,hadoop,machine learning,spark},
  file = {/home/peterprescott/Zotero/storage/7TYQJH7W/Armbrust et al. - 2015 - Spark SQL Relational Data Processing in Spark.pdf}
}

@inproceedings{MZahariaEtAl2012,
  title = {Resilient {{Distributed Datasets}}: A {{Fault}}-{{Tolerant Abstraction}} for {{In}}-{{Memory Cluster Computing}}},
  shorttitle = {Resilient {{Distributed Datasets}}},
  booktitle = {9th \{\vphantom\}{{USENIX}}\vphantom\{\} {{Symposium}} on {{Networked Systems Design}} and {{Implementation}} (\{\vphantom\}{{NSDI}}\vphantom\{\} 12)},
  author = {Zaharia, Matei and Chowdhury, Mosharaf and Das, Tathagata and Dave, Ankur and Ma, Justin and McCauly, Murphy and Franklin, Michael J. and Shenker, Scott and Stoica, Ion},
  year = {2012},
  pages = {15--28},
  langid = {english},
  file = {/home/peterprescott/Zotero/storage/ZVCTGM22/Zaharia et al. - 2012 - Resilient Distributed Datasets A Fault-Tolerant A.pdf}
}

@inproceedings{SGhemawatEtAl2003,
  title = {The {{Google}} File System},
  booktitle = {Proceedings of the Nineteenth {{ACM}} Symposium on {{Operating}} Systems Principles},
  author = {Ghemawat, Sanjay and Gobioff, Howard and Leung, Shun-Tak},
  year = {2003},
  pages = {29--43},
  file = {/home/peterprescott/Zotero/storage/F3RVTP34/Ghemawat et al. - 2003 - The Google file system.pdf;/home/peterprescott/Zotero/storage/UX27GFN7/945445.html}
}


